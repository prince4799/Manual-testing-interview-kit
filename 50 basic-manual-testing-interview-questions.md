| **#** | **Question** | **Answer** |
|------|--------------|------------|
| 1 | What is the difference between verification and validation? | Verification ensures the product is built right (reviews, walkthroughs); validation ensures the right product is built (actual testing). |
| 2 | Explain the Software Testing Life Cycle (STLC). | STLC includes Requirement Analysis, Test Planning, Test Case Design, Environment Setup, Test Execution, and Test Closure. |
| 3 | What are the different levels of testing? | Unit, Integration, System, and Acceptance Testing. Each focuses on different scopes and stages of the application. |
| 4 | What is the difference between functional and non-functional testing? | Functional testing checks what the system does; non-functional tests how it performs (e.g., performance, usability). |
| 5 | How do you differentiate between severity and priority? | Severity: impact of the bug; Priority: urgency to fix. A high severity issue may have low priority and vice versa. |
| 6 | What is exploratory testing? | Unscripted testing to explore the app and find hidden bugs, often based on experience and intuition. |
| 7 | What is acceptance testing? | It's the final testing phase done by end-users or clients to verify the system meets business needs. |
| 8 | What is regression testing? | Re-testing the unchanged parts of the app to ensure new changes haven't broken existing functionality. |
| 9 | What is a test plan? | A document outlining scope, approach, resources, and schedule for testing activities. |
| 10 | Smoke vs. Sanity testing? | Smoke: basic tests to check app stability. Sanity: quick checks after fixes to verify specific functionalities. |
| 11 | How do you write effective test cases? | Use clear steps, expected results, and preconditions. Cover positive, negative, and boundary scenarios. |
| 12 | Characteristics of a good test case? | Clear, concise, traceable to requirements, reusable, and easy to execute. |
| 13 | Test case vs. Test scenario? | Test case: detailed steps to test a feature. Test scenario: high-level functionality to test. |
| 14 | Prioritize test cases under tight deadlines? | Focus on high-risk, high-priority, and frequently used functionalities first. |
| 15 | What is boundary value analysis? | Testing at edge values (e.g., min, max). For 1–100, test 0,1,2 and 99,100,101. |
| 16 | What is equivalence partitioning? | Dividing inputs into valid/invalid classes and testing one from each class. |
| 17 | Key fields in a bug report? | ID, Summary, Steps, Expected vs Actual, Severity, Priority, Environment, Attachments. |
| 18 | Bug life cycle stages? | New → Assigned → Open → Fixed → Retest → Closed/Reopen → Deferred/Rejected. |
| 19 | Developer disagrees with defect? | Provide evidence: logs, screenshots, steps. Discuss and escalate if needed. |
| 20 | What is defect leakage? | Defect missed in testing but found in production. Minimize by better coverage. |
| 21 | Describe your project testing process. | Involved in analyzing requirements, creating test cases, executing them, logging bugs, and reporting. |
| 22 | Documents used in testing? | SRS, BRD, Test Plan, RTM, Test Cases, Bug Reports. |
| 23 | How to ensure test coverage? | Use RTM to map requirements to test cases and perform peer reviews. |
| 24 | A challenging bug you found? | Found a critical login bypass due to session reuse; reported with evidence and helped dev fix it. |
| 25 | Collaboration with developers/BA? | Attend stand-ups, clarify doubts, log detailed defects, and use tools like JIRA/Confluence. |
| 26 | Changing requirements handling? | Update test cases accordingly, inform stakeholders, and prioritize impacted areas. |
| 27 | Participated in UAT? | Supported end-users with testing, resolved issues, and documented feedback for dev team. |
| 28 | Agile or Waterfall experience? | Worked in Agile; involved in sprint planning, daily scrums, and sprint reviews. |
| 29 | Incomplete requirements? | Communicate with BAs or product owners, raise clarifications, and document assumptions. |
| 30 | How do you do end-to-end testing? | Test from start to finish including integrations, databases, and real user flows. |
| 31 | What is risk-based testing? | Prioritize tests based on impact and likelihood of failure. |
| 32 | How to estimate testing effort? | Based on test case count, complexity, past experience, and team capacity. |
| 33 | Compatibility testing? | Test on different browsers, OS, and devices manually or using tools like BrowserStack. |
| 34 | Role of RTM? | Ensures each requirement is covered by test cases and helps track test progress. |
| 35 | Root cause analysis? | Analyze defect origin, logs, and test gaps to prevent recurrence. |
| 36 | What is shift-left testing? | Start testing early in the development cycle to catch issues sooner. |
| 37 | Handling flaky test cases? | Identify patterns, isolate environment issues, and improve stability. |
| 38 | Alpha vs. Beta testing? | Alpha: internal testing before release. Beta: by users after release in limited scope. |
| 39 | Test strategy vs. test plan? | Strategy: high-level approach. Plan: detailed execution steps and resources. |
| 40 | Test metrics examples? | Test coverage, defect density, test execution rate, defect leakage. |
| 41 | Tools used? | JIRA for bug tracking, TestRail for test management, Confluence for documentation. |
| 42 | How do you manage test data? | Create, reuse, and clean up data using test scripts or manually in lower environments. |
| 43 | Used Confluence? | Yes, for test documentation, meeting notes, and requirement references. |
| 44 | JIRA custom workflow experience? | Customized statuses like “QA Verified” and added fields for better defect tracking. |
| 45 | Challenges in writing test cases? | Vague requirements, time constraints, and covering edge cases. |
| 46 | Keeping up with domain knowledge? | Read product docs, attend domain sessions, and interact with SMEs. |
| 47 | Manual non-functional testing? | Performed usability and basic performance checks manually. |
| 48 | Manual browser testing approach? | Test app on different browsers/resolutions using real devices or emulators. |
| 49 | Ensuring quality under deadlines? | Risk-based testing, focus on critical paths, and quick regression. |
| 50 | Qualities of a good manual tester? | Detail-oriented, analytical, curious, communicative, and user-focused. |
